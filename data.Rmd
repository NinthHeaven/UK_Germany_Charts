---
title: "Milestone 4"
author: "Saul Soto"
date: "3/6/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(knitr)
library(spotifyr)
library(lubridate)
library(readxl)
library(janitor)
library(rvest)
Sys.setenv(SPOTIFY_CLIENT_ID = '1ebacb60ef2044ccadab18602f7c0b8f')
Sys.setenv(SPOTIFY_CLIENT_SECRET = '6fb54464f8dc45c88387a4fadde775db')

access_token <- get_spotify_access_token()

# So it turns out that I am completely unable to get any data from Germany or
# the UK because I have a USA Spotify account. What I will do for this milestone
# is get the spotify top 200 tracks for the past 3 Februarys (Spotify only has
# data up until 2017) and store them in their own dataframe (UK and Germany).
# Since the dataframes do not give me details about the genre or any analysis,
# that means I'll have to do it individually for every song, which is a little
# absurd given the time for this project. My plan is to hopefully get Spotify to
# give me access to the global market, if not I will narrow my project.

top_200_2020_uk <- read.csv("raw-data/regional-gb-daily-latest.csv", skip = 1) %>%
  clean_names() %>%
  select(1:3) %>%
  mutate(year = rep("2020"))

top_200_2019_uk <- read.csv("raw-data/regional-gb-daily-2019-02-28.csv", skip = 1) %>%
  clean_names() %>%
  select(1:3) %>%
  mutate(year = rep("2019"))

top_200_2018_uk <- read.csv("raw-data/regional-gb-daily-2018-02-28.csv", skip = 1) %>%
  clean_names() %>%
  select(1:3) %>%
  mutate(year = rep("2018"))

top_200_2017_uk <- read.csv("raw-data/regional-gb-daily-2017-02-28.csv", skip = 1) %>%
  clean_names() %>%
  select(1:3) %>%
  mutate(year = rep("2017"))

# Here is the Germany data that I will hopefully end up using for my final
# project. I do have some other ideas, such as compare the analysis of the EDM
# audio tracks that do make it to the US top 200 on Spotify and compare it to
# the analysis of whatever genres dominate the US charts.

top_200_2020_ger <- read.csv("raw-data-ger/regional-de-daily-latest.csv", skip = 1) %>%
  clean_names() %>%
  select(1:3) %>%
  mutate(year = rep("2020"))

top_200_2019_ger <- read.csv("raw-data-ger/regional-de-daily-2019-02-28.csv",
                             skip = 1) %>%
  clean_names() %>%
  select(1:3) %>%
  mutate(year = rep("2019"))

top_200_2018_ger <- read.csv("raw-data-ger/regional-de-daily-2018-02-28.csv", 
                             skip = 1) %>%
  clean_names() %>%
  select(1:3) %>%
  mutate(year = rep("2018"))

top_200_2017_ger <- read.csv("raw-data-ger/regional-de-daily-2017-02-28.csv",
                             skip = 1) %>%
  clean_names() %>%
  select(1:3) %>%
  mutate(year = rep("2017"))

# Alternatively, I can also try to see which songs match, and get the analytics
# of the tracks that match and what position they rank in in the UK and Ger
# markets retrospectively. Of course, this can only be possible if the songs are
# also available in the US market. I can also just do what I originally wanted
# to with the 2000-2010 data and just focus on the data I've collected just now.

top_uk_total <- rbind(top_200_2020_uk, top_200_2019_uk, 
                    top_200_2018_uk, top_200_2017_uk)
total_ger_total <- rbind(top_200_2020_ger, top_200_2019_ger,
                         top_200_2018_ger, top_200_2017_ger)
```

```{r ukcharts, echo=FALSE}
# I added this because I thought it would fix the problem with spotify returning
# NULL observations, but it did not :(

options(stringsAsFactors = FALSE)

# Thank you Mitchell for the lines of code below!!

uk2000_hits <- "http://www.uk-charts.top-source.info/top-100-2000.shtml" %>%
  read_html()

uk_2000_data <- html_nodes(uk2000_hits, "td") %>% 
  html_text()

# Okay so contrary to my belief, rep will not be the best way to split the list
# up, but the as.data.frame function will automatically continue to split the
# first three rows into a separate column. Perhaps there is another way to do
# this, but I like this method for now.

uk_2000_data <- as.data.frame(split(uk_2000_data, 1:3)) %>% 
  rename(position = X1,
         artist = X2,
         title = X3)

## Test out if Spotify will give me the genres of titles. This does not work at
## the moment, but I believe that once I figure this aspect out, it shall be
## easy to move onwards with the data-gathering.

# get_track_audio_features(uk_2000_data$title)

## Get tracks from 2001-2010 in UK

uk2001_hits <- "http://www.uk-charts.top-source.info/top-100-2001.shtml" %>%
  read_html()

uk2001_hits <- html_nodes(uk2001_hits, "td") %>%
  html_text()

uk2001_data <- as.data.frame(split(uk2001_hits, 1:3)) %>% 
  rename(position = X1,
         artist = X2,
         title = X3)

uk2002_hits <- "http://www.uk-charts.top-source.info/top-100-2002.shtml" %>%
  read_html()

uk2002_hits <- html_nodes(uk2002_hits, "td") %>%
  html_text()

uk2002_data <- as.data.frame(split(uk2002_hits, 1:3)) %>%
  rename(position = X1,
         artist = X2,
         title = X3)

uk2003_hits <- "http://www.uk-charts.top-source.info/top-100-2003.shtml" %>%
  read_html()

uk2003_hits <- html_nodes(uk2003_hits, "td") %>%
  html_text()

uk2003_data <- as.data.frame(split(uk2003_hits, 1:3)) %>%
  rename(position = X1,
         artist = X2,
         title = X3)

uk2004_hits <- "http://www.uk-charts.top-source.info/top-100-2004.shtml" %>%
  read_html()

uk2004_hits <- html_nodes(uk2004_hits, "td") %>%
  html_text()

uk2004_data <- as.data.frame(split(uk2004_hits, 1:3)) %>%
  rename(position = X1,
         artist = X2,
         title = X3)

uk2005_hits <- "http://www.uk-charts.top-source.info/top-100-2005.shtml" %>%
  read_html()

uk2005_hits <- html_nodes(uk2005_hits, "td") %>%
  html_text()

uk2005_data <- as.data.frame(split(uk2005_hits, 1:3)) %>%
  rename(position = X1,
         artist = X2,
         title = X3)

uk2006_hits <- "http://www.uk-charts.top-source.info/top-100-2006.shtml" %>%
  read_html()

uk2006_hits <- html_nodes(uk2006_hits, "td") %>%
  html_text()

uk2006_data <- as.data.frame(split(uk2006_hits, 1:3)) %>%
  rename(position = X1,
         artist = X2,
         title = X3)

uk2007_hits <- "http://www.uk-charts.top-source.info/top-100-2007.shtml" %>%
  read_html()

uk2007_hits <- html_nodes(uk2007_hits, "td") %>%
  html_text()

uk2007_data <- as.data.frame(split(uk2007_hits, 1:3)) %>%
  rename(position = X1,
         artist = X2,
         title = X3)

uk2008_hits <- "http://www.uk-charts.top-source.info/top-100-2008.shtml" %>%
  read_html()

uk2008_hits <- html_nodes(uk2008_hits, "td") %>%
  html_text()

uk2008_data <- as.data.frame(split(uk2008_hits, 1:3)) %>%
  rename(position = X1,
         artist = X2,
         title = X3)

uk2009_hits <- "http://www.uk-charts.top-source.info/top-100-2009.shtml" %>%
  read_html()

uk2009_hits <- html_nodes(uk2009_hits, "td") %>%
  html_text()

uk2009_data <- as.data.frame(split(uk2009_hits, 1:3)) %>%
  rename(position = X1,
         artist = X2,
         title = X3)

uk2010_hits <- "http://www.uk-charts.top-source.info/top-100-2010.shtml" %>%
  read_html()

uk2010_hits <- html_nodes(uk2010_hits, "td") %>%
  html_text()

uk2010_data <- as.data.frame(split(uk2010_hits, 1:3)) %>%
  rename(position = X1,
         artist = X2,
         title = X3)

# Testing the Germany data set

```

# Data Gathered Thus Far
As you can see above, the data I have only consists of the top 100 music hits in the UK from the year 2000. Why has such little data been gathered? I wanted to show what the rest of the code would look like once I gather all the data from 2000-2010 from the UK and Germany. Although it doesn't look like much code, this will probably be over a thousand lines long by the end of the week. 

# How did you get this fine piece of data?
Thank you for asking stranger. I got this data by scraping the list from this website: http://www.uk-charts.top-source.info/index.shtml. I will continue to get data from this website from 2000-2010 for the UK, then I will use https://www.offiziellecharts.de to get the data for Germany. 

# Why did you stop after 1 year?
This was mostly me just testing the waters of what I can do with the data I gathered. Obviously this isn't the final project, it's not even %5 of the final project. I still have to scrape 1,900 more songs, and probably bind all of the data into two big chunks of 10 years of observations for Germany and UK. However, I will have to figure out how to get Spotify to analyze the data in the "titles" section of the UK data (it currently returns a lot of NULL observations, so I will have to read more of the sportifyr documentation). I should have all the data I want by tomorrow, and I will have to figure out how to get spotify to read that data over the weekend so I can start making some nice looking graphs. Overall, I think I am pretty happy where I am with this project.

# Are you going to keep updating this repo?

Of course! Everything pushed after today is just me gathering data from the UK and Germany charts. Hopefully by Sunday I will have created two massive chunks of data, but that is if I can get the spotify function to work. It is crucial for me to do this because most of the spotify commands involving track analysis can only take 100 observations at once.

Here is the repo for your convenience:
https://github.com/NinthHeaven/milestone4
